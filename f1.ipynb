{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020\n",
      "Dataset rohanrao/formula-1-world-championship-1950-2020 downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# activate .venv environment\n",
    "# windows: .\\venv\\Scripts\\activate\n",
    "# mac: source .venv/bin/activate\n",
    "# then pip install kaggle, pip install pyspark and pip install findspark inside .venv\n",
    "# move kaggle.json file into ~/.kaggle\n",
    "# then you can run data\n",
    "\n",
    "import kaggle\n",
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "dataset = \"rohanrao/formula-1-world-championship-1950-2020\"\n",
    "\n",
    "kaggle.api.dataset_download_files(dataset, path='./', unzip=True)\n",
    "\n",
    "print(f\"Dataset {dataset} downloaded successfully!\")\n",
    "\n",
    " # create spark session\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Driver_Performance_Prediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = \"results.csv\"\n",
    "qualifying = \"qualifying.csv\"\n",
    "lap_times = \"lap_times.csv\"\n",
    "pit_stops = \"pit_stops.csv\"\n",
    "driver_standings = \"driver_standings.csv\"\n",
    "races = \"races.csv\"\n",
    "constructors = \"constructors.csv\"\n",
    "circuits = \"circuits.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-------------+------+----+--------------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+\n",
      "|resultId|raceId|driverId|constructorId|number|grid|final_position|positionText|positionOrder|points|laps|       time|milliseconds|fastestLap|rank|fastestLapTime|fastestLapSpeed|statusId|\n",
      "+--------+------+--------+-------------+------+----+--------------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+\n",
      "|       1|    18|       1|            1|    22|   1|             1|           1|            1|  10.0|  58|1:34:50.616|     5690616|        39|   2|      1:27.452|        218.300|       1|\n",
      "|       2|    18|       2|            2|     3|   5|             2|           2|            2|   8.0|  58|     +5.478|     5696094|        41|   3|      1:27.739|        217.586|       1|\n",
      "|       3|    18|       3|            3|     7|   7|             3|           3|            3|   6.0|  58|     +8.163|     5698779|        41|   5|      1:28.090|        216.719|       1|\n",
      "|       4|    18|       4|            4|     5|  11|             4|           4|            4|   5.0|  58|    +17.181|     5707797|        58|   7|      1:28.603|        215.464|       1|\n",
      "|       5|    18|       5|            1|    23|   3|             5|           5|            5|   4.0|  58|    +18.014|     5708630|        43|   1|      1:27.418|        218.385|       1|\n",
      "|       6|    18|       6|            3|     8|  13|             6|           6|            6|   3.0|  57|         \\N|          \\N|        50|  14|      1:29.639|        212.974|      11|\n",
      "|       7|    18|       7|            5|    14|  17|             7|           7|            7|   2.0|  55|         \\N|          \\N|        54|   8|      1:29.534|        213.224|       5|\n",
      "|       8|    18|       8|            6|     1|  15|             8|           8|            8|   1.0|  53|         \\N|          \\N|        20|   4|      1:27.903|        217.180|       5|\n",
      "|      23|    19|       8|            6|     1|   2|             1|           1|            1|  10.0|  56|1:31:18.555|     5478555|        37|   2|      1:35.405|        209.158|       1|\n",
      "|      24|    19|       9|            2|     4|   4|             2|           2|            2|   8.0|  56|    +19.570|     5498125|        39|   6|      1:35.921|        208.033|       1|\n",
      "|      25|    19|       5|            1|    23|   8|             3|           3|            3|   6.0|  56|    +38.450|     5517005|        19|   7|      1:35.922|        208.031|       1|\n",
      "|      26|    19|      15|            7|    11|   3|             4|           4|            4|   5.0|  56|    +45.832|     5524387|        53|   8|      1:36.068|        207.715|       1|\n",
      "|      27|    19|       1|            1|    22|   9|             5|           5|            5|   4.0|  56|    +46.548|     5525103|        53|   3|      1:35.462|        209.033|       1|\n",
      "|      28|    19|       2|            2|     3|   5|             6|           6|            6|   3.0|  56|    +49.833|     5528388|        55|   1|      1:35.366|        209.244|       1|\n",
      "|      29|    19|      17|            9|    10|   6|             7|           7|            7|   2.0|  56|  +1:08.130|     5546685|        53|  12|      1:36.696|        206.366|       1|\n",
      "|      30|    19|       4|            4|     5|   7|             8|           8|            8|   1.0|  56|  +1:10.041|     5548596|        40|  10|      1:36.288|        207.240|       1|\n",
      "|      31|    19|      14|            9|     9|  12|             9|           9|            9|   0.0|  56|  +1:16.220|     5554775|        55|   9|      1:36.206|        207.417|       1|\n",
      "|      32|    19|      18|           11|    16|  11|            10|          10|           10|   0.0|  56|  +1:26.214|     5564769|        56|   4|      1:35.715|        208.481|       1|\n",
      "|      33|    19|      12|            4|     6|  13|            11|          11|           11|   0.0|  56|  +1:32.202|     5570757|        52|  15|      1:36.956|        205.812|       1|\n",
      "|      34|    19|      21|           10|    21|  17|            12|          12|           12|   0.0|  55|         \\N|          \\N|        52|  16|      1:36.962|        205.800|      11|\n",
      "+--------+------+--------+-------------+------+----+--------------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType\n",
    "result_df = spark.read.csv(results, header=True, inferSchema=True)\n",
    "\n",
    "# need to remove \\N\n",
    "result_df = result_df.dropna()\n",
    "result_df = result_df.drop('number', 'positionText', 'time', 'rank','statusId', 'fastestLap', 'fastestLapSpeed', 'milliseconds', 'laps', 'points')\n",
    "result_df = df.withColumn('position', col('position').cast(IntegerType()))\n",
    "result_df = result_df.dropna()\n",
    "result_df = result_df.withColumnRenamed('position', 'final_position')\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+-------------+-------------------+\n",
      "|qualifyId|raceId|driverId|constructorId|qualifying_position|\n",
      "+---------+------+--------+-------------+-------------------+\n",
      "|        1|    18|       1|            1|                  1|\n",
      "|        2|    18|       9|            2|                  2|\n",
      "|        3|    18|       5|            1|                  3|\n",
      "|        4|    18|      13|            6|                  4|\n",
      "|        5|    18|       2|            2|                  5|\n",
      "|        6|    18|      15|            7|                  6|\n",
      "|        7|    18|       3|            3|                  7|\n",
      "|        8|    18|      14|            9|                  8|\n",
      "|        9|    18|      10|            7|                  9|\n",
      "|       10|    18|      20|            5|                 10|\n",
      "|       11|    18|      22|           11|                 11|\n",
      "|       12|    18|       4|            4|                 12|\n",
      "|       13|    18|      18|           11|                 13|\n",
      "|       14|    18|       6|            3|                 14|\n",
      "|       15|    18|      17|            9|                 15|\n",
      "|       16|    18|       8|            6|                 16|\n",
      "|       17|    18|      21|           10|                 17|\n",
      "|       18|    18|       7|            5|                 18|\n",
      "|       19|    18|      16|           10|                 19|\n",
      "|       20|    18|      11|            8|                 20|\n",
      "+---------+------+--------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "[('qualifyId', 'int'), ('raceId', 'int'), ('driverId', 'int'), ('constructorId', 'int'), ('qualifying_position', 'int')]\n"
     ]
    }
   ],
   "source": [
    "qualifying_df = spark.read.csv(qualifying, header=True, inferSchema=True)\n",
    "qualifying_df = qualifying_df.drop('number', 'q1', 'q2', 'q3')\n",
    "qualifying_df = qualifying_df.withColumnRenamed('position', 'qualifying_position')\n",
    "qualifying_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+------------+--------+\n",
      "|raceId|driverId|lap|lap_position|lap_time|\n",
      "+------+--------+---+------------+--------+\n",
      "|   841|      20|  1|           1|1:38.109|\n",
      "|   841|      20|  2|           1|1:33.006|\n",
      "|   841|      20|  3|           1|1:32.713|\n",
      "|   841|      20|  4|           1|1:32.803|\n",
      "|   841|      20|  5|           1|1:32.342|\n",
      "|   841|      20|  6|           1|1:32.605|\n",
      "|   841|      20|  7|           1|1:32.502|\n",
      "|   841|      20|  8|           1|1:32.537|\n",
      "|   841|      20|  9|           1|1:33.240|\n",
      "|   841|      20| 10|           1|1:32.572|\n",
      "|   841|      20| 11|           1|1:32.669|\n",
      "|   841|      20| 12|           1|1:32.902|\n",
      "|   841|      20| 13|           1|1:33.698|\n",
      "|   841|      20| 14|           3|1:52.075|\n",
      "|   841|      20| 15|           4|1:38.385|\n",
      "|   841|      20| 16|           2|1:31.548|\n",
      "|   841|      20| 17|           1|1:30.800|\n",
      "|   841|      20| 18|           1|1:31.810|\n",
      "|   841|      20| 19|           1|1:31.018|\n",
      "|   841|      20| 20|           1|1:31.055|\n",
      "+------+--------+---+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lap_times_df = spark.read.csv(lap_times, header=True, inferSchema=True)\n",
    "lap_times_df = lap_times_df.drop('milliseconds')\n",
    "lap_times_df = lap_times_df.withColumnRenamed('time', 'lap_time').withColumnRenamed('position', 'lap_position').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+---+-------------+\n",
      "|raceId|driverId|pit_stop|lap|stop_duration|\n",
      "+------+--------+--------+---+-------------+\n",
      "|   841|     153|       1|  1|       26.898|\n",
      "|   841|      30|       1|  1|       25.021|\n",
      "|   841|      17|       1| 11|       23.426|\n",
      "|   841|       4|       1| 12|       23.251|\n",
      "|   841|      13|       1| 13|       23.842|\n",
      "|   841|      22|       1| 13|       23.643|\n",
      "|   841|      20|       1| 14|       22.603|\n",
      "|   841|     814|       1| 14|       24.863|\n",
      "|   841|     816|       1| 14|       25.259|\n",
      "|   841|      67|       1| 15|       25.342|\n",
      "|   841|       2|       1| 15|       22.994|\n",
      "|   841|       1|       1| 16|       23.227|\n",
      "|   841|     808|       1| 16|       24.535|\n",
      "|   841|       3|       1| 16|       23.716|\n",
      "|   841|     155|       1| 16|       24.064|\n",
      "|   841|      16|       1| 16|       25.978|\n",
      "|   841|      15|       1| 16|       24.899|\n",
      "|   841|      18|       1| 17|       16.867|\n",
      "|   841|     153|       2| 17|       24.463|\n",
      "|   841|       5|       1| 17|       24.865|\n",
      "+------+--------+--------+---+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pit_stops_df = spark.read.csv(pit_stops, header=True, inferSchema=True)\n",
    "pit_stops_df = pit_stops_df.drop('milliseconds', 'time')\n",
    "pit_stops_df = pit_stops_df.withColumnRenamed('duration', 'stop_duration')\n",
    "pit_stops_df = pit_stops_df.withColumnRenamed('stop', 'pit_stop')\n",
    "pit_stops_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+--------+------+\n",
      "|driverStandingsId|raceId|driverId|points|\n",
      "+-----------------+------+--------+------+\n",
      "|                1|    18|       1|  10.0|\n",
      "|                2|    18|       2|   8.0|\n",
      "|                3|    18|       3|   6.0|\n",
      "|                4|    18|       4|   5.0|\n",
      "|                5|    18|       5|   4.0|\n",
      "|                6|    18|       6|   3.0|\n",
      "|                7|    18|       7|   2.0|\n",
      "|                8|    18|       8|   1.0|\n",
      "|                9|    19|       1|  14.0|\n",
      "|               10|    19|       2|  11.0|\n",
      "|               11|    19|       3|   6.0|\n",
      "|               12|    19|       4|   6.0|\n",
      "|               13|    19|       5|  10.0|\n",
      "|               14|    19|       6|   3.0|\n",
      "|               15|    19|       7|   2.0|\n",
      "|               16|    19|       8|  11.0|\n",
      "|               17|    19|       9|   8.0|\n",
      "|               18|    19|      15|   5.0|\n",
      "|               19|    19|      17|   2.0|\n",
      "|               20|    19|      14|   0.0|\n",
      "+-----------------+------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "[('driverStandingsId', 'int'), ('raceId', 'int'), ('driverId', 'int'), ('points', 'double')]\n"
     ]
    }
   ],
   "source": [
    "# driver position is driver's championship standing\n",
    "driver_standings_df = spark.read.csv(driver_standings, header=True, inferSchema=True)\n",
    "driver_standings_df = driver_standings_df.drop('position','positionText', 'wins')\n",
    "#driver_standings_df = driver_standings_df.withColumnRenamed('position', 'driver_position')\n",
    "driver_standings_df.show()\n",
    "print(driver_standings_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+\n",
      "|raceId|circuitId|                name|\n",
      "+------+---------+--------------------+\n",
      "|     1|        1|Australian Grand ...|\n",
      "|     2|        2|Malaysian Grand Prix|\n",
      "|     3|       17|  Chinese Grand Prix|\n",
      "|     4|        3|  Bahrain Grand Prix|\n",
      "|     5|        4|  Spanish Grand Prix|\n",
      "|     6|        6|   Monaco Grand Prix|\n",
      "|     7|        5|  Turkish Grand Prix|\n",
      "|     8|        9|  British Grand Prix|\n",
      "|     9|       20|   German Grand Prix|\n",
      "|    10|       11|Hungarian Grand Prix|\n",
      "|    11|       12| European Grand Prix|\n",
      "|    12|       13|  Belgian Grand Prix|\n",
      "|    13|       14|  Italian Grand Prix|\n",
      "|    14|       15|Singapore Grand Prix|\n",
      "|    15|       22| Japanese Grand Prix|\n",
      "|    16|       18|Brazilian Grand Prix|\n",
      "|    17|       24|Abu Dhabi Grand Prix|\n",
      "|    18|        1|Australian Grand ...|\n",
      "|    19|        2|Malaysian Grand Prix|\n",
      "|    20|        3|  Bahrain Grand Prix|\n",
      "+------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "races_df = spark.read.csv(races, header=True, inferSchema=True)\n",
    "races_df = races_df.drop('year','date','time', 'round','url', 'fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', 'fp3_time', 'quali_date', 'quali_time', 'sprint_date', 'sprint_time')\n",
    "races_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|constructorId|       name|\n",
      "+-------------+-----------+\n",
      "|            1|    McLaren|\n",
      "|            2| BMW Sauber|\n",
      "|            3|   Williams|\n",
      "|            4|    Renault|\n",
      "|            5| Toro Rosso|\n",
      "|            6|    Ferrari|\n",
      "|            7|     Toyota|\n",
      "|            8|Super Aguri|\n",
      "|            9|   Red Bull|\n",
      "|           10|Force India|\n",
      "|           11|      Honda|\n",
      "|           12|     Spyker|\n",
      "|           13|        MF1|\n",
      "|           14| Spyker MF1|\n",
      "|           15|     Sauber|\n",
      "|           16|        BAR|\n",
      "|           17|     Jordan|\n",
      "|           18|    Minardi|\n",
      "|           19|     Jaguar|\n",
      "|           20|      Prost|\n",
      "+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "constructors_df = spark.read.csv(constructors, header=True, inferSchema=True)\n",
    "constructors_df = constructors_df.drop('url', 'nationality', 'constructorRef')\n",
    "constructors_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+---+\n",
      "|circuitId|     lat|      lng|alt|\n",
      "+---------+--------+---------+---+\n",
      "|        1|-37.8497|  144.968| 10|\n",
      "|        2| 2.76083|  101.738| 18|\n",
      "|        3| 26.0325|  50.5106|  7|\n",
      "|        4|   41.57|  2.26111|109|\n",
      "|        5| 40.9517|   29.405|130|\n",
      "|        6| 43.7347|  7.42056|  7|\n",
      "|        7|    45.5| -73.5228| 13|\n",
      "|        8| 46.8642|  3.16361|228|\n",
      "|        9| 52.0786| -1.01694|153|\n",
      "|       10| 49.3278|  8.56583|103|\n",
      "|       11| 47.5789|  19.2486|264|\n",
      "|       12| 39.4589|-0.331667|  4|\n",
      "|       13| 50.4372|  5.97139|401|\n",
      "|       14| 45.6156|  9.28111|162|\n",
      "|       15|  1.2914|  103.864| 18|\n",
      "|       16| 35.3717|  138.927|583|\n",
      "|       17| 31.3389|   121.22|  5|\n",
      "|       18|-23.7036| -46.6997|785|\n",
      "|       19|  39.795| -86.2347|223|\n",
      "|       20| 50.3356|   6.9475|578|\n",
      "+---------+--------+---------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "circuits_df = spark.read.csv(circuits, header=True, inferSchema=True)\n",
    "circuits_df = circuits_df.drop('circuitRef', 'name', 'location', 'url', 'country')\n",
    "circuits_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
